{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af0cf8e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:28:33.675174Z",
     "iopub.status.busy": "2025-06-02T14:28:33.674834Z",
     "iopub.status.idle": "2025-06-02T14:28:33.686053Z",
     "shell.execute_reply": "2025-06-02T14:28:33.684983Z"
    },
    "papermill": {
     "duration": 0.017556,
     "end_time": "2025-06-02T14:28:33.687671",
     "exception": false,
     "start_time": "2025-06-02T14:28:33.670115",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "run_number = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c340ffca-237a-414f-a5d1-6d26853a4848",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T14:28:33.697035Z",
     "iopub.status.busy": "2025-06-02T14:28:33.696707Z",
     "iopub.status.idle": "2025-06-02T14:34:19.193025Z",
     "shell.execute_reply": "2025-06-02T14:34:19.191818Z"
    },
    "papermill": {
     "duration": 345.50355,
     "end_time": "2025-06-02T14:34:19.194613",
     "exception": false,
     "start_time": "2025-06-02T14:28:33.691063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/gnn_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 7798,Val: 3157,Test: 3367,Val + Train combined: 10955\n",
      "\n",
      "Data loading completed\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter optimization...\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_dim': 103, 'dropout_rate': 0.1945178681889085, 'aggregator_type': 'pool', 'lr': 0.002066595185419995, 'batch_size': 128, 'n_hidden_layers': 1, 'lr_scheduler': 'ExponentialLR', 'activation': 'RELU', 'gamma_exp': 0.9872745703157462}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders done.\n",
      "Retraining using best parameters...\n",
      "Number of available node features (in_feats): 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2829465/453001992.py:201: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()       # initializing the gradient scaler\n",
      "/tmp/ipykernel_2829465/453001992.py:215: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():    # automatically selects the appropriate floating-point precision (to optimize performance - speeds up training, reduces memory usage)\n",
      "/home/ubuntu/miniconda3/envs/gnn_project/lib/python3.10/site-packages/dgl/backend/pytorch/sparse.py:157: FutureWarning: `torch.cuda.amp.autocast_mode._cast(value, dtype)` is deprecated. Please use `torch.amp.autocast_mode._cast(value, 'cuda', dtype)` instead.\n",
      "  return th.cuda.amp.autocast_mode._cast(\n",
      "/home/ubuntu/miniconda3/envs/gnn_project/lib/python3.10/site-packages/dgl/backend/pytorch/sparse.py:148: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  return th.cuda.amp.autocast(enabled=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2829465/453001992.py:247: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():    # automatically selects the appropriate floating-point precision (to optimize performance - speeds up training, reduces memory usage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000Train loss: 0.6853Val loss: 0.6783Val accuracy: 47.58% MCC: 0.14615715537430665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000Train loss: 0.6382Val loss: 0.6239Val accuracy: 68.77% MCC: 0.3386692121693634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000Train loss: 0.6143Val loss: 0.6251Val accuracy: 69.46% MCC: 0.351068953066582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000Train loss: 0.6021Val loss: 0.6207Val accuracy: 69.27% MCC: 0.34793147970787275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000Train loss: 0.5964Val loss: 0.6106Val accuracy: 69.69% MCC: 0.36386765223860856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000Train loss: 0.5891Val loss: 0.6428Val accuracy: 68.07% MCC: 0.32031045172103995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000Train loss: 0.5778Val loss: 0.6263Val accuracy: 68.83% MCC: 0.33688021771099197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000Train loss: 0.5792Val loss: 0.6258Val accuracy: 68.32% MCC: 0.32455560480731044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000Train loss: 0.5818Val loss: 0.6304Val accuracy: 68.58% MCC: 0.3300440403252896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000Train loss: 0.5752Val loss: 0.6126Val accuracy: 68.67% MCC: 0.3486664071610554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000Train loss: 0.5734Val loss: 0.6132Val accuracy: 68.70% MCC: 0.3474814885917558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000Train loss: 0.5740Val loss: 0.6106Val accuracy: 68.61% MCC: 0.34922317503247163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000Train loss: 0.5731Val loss: 0.6104Val accuracy: 69.02% MCC: 0.35812700759980903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000Train loss: 0.5721Val loss: 0.6152Val accuracy: 68.36% MCC: 0.33220074767825175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/1000Train loss: 0.5681Val loss: 0.6228Val accuracy: 68.04% MCC: 0.32159957578513954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000Train loss: 0.5640Val loss: 0.6101Val accuracy: 68.20% MCC: 0.346666560461126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/1000Train loss: 0.5701Val loss: 0.6121Val accuracy: 68.26% MCC: 0.33727958436205585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/1000Train loss: 0.5615Val loss: 0.6120Val accuracy: 69.12% MCC: 0.35614911979545666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/1000Train loss: 0.5681Val loss: 0.6128Val accuracy: 68.55% MCC: 0.3463133379746788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000Train loss: 0.5638Val loss: 0.6138Val accuracy: 69.15% MCC: 0.34903783490992357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 96\n",
      "The best epoch was 16\n",
      "Training done.\n",
      "Final training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done.\n",
      "Evaluating on test_dataset\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.6049089354497416\n",
      "Accuracy: 0.6902286902286903, Precision: 0.7402247191011236, Recall: 0.7798295454545454, F1-Score: 0.7595111828452847, MCC: 0.3260853509735427, ROC-AUC: 0.7308095270433419\n",
      "Evaluation done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "os.environ[\"TORCHDYNAMO_DISABLE\"] = \"1\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "import torch\n",
    "torch.use_deterministic_algorithms(True)\n",
    "torch.cuda.empty_cache()\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ExponentialLR, StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "torch._dynamo.config.suppress_errors = True\n",
    "import random\n",
    "\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import dgl\n",
    "from dgl.nn import SAGEConv, GlobalAttentionPooling\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "# subclass of torch.nn.Module\n",
    "\n",
    "# subclass of torch.nn.Module\n",
    "\n",
    "\n",
    "\n",
    "class SAGE(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_feats,       # input feature dimensions (anotation size)\n",
    "        out_feats,    # the same thing as hidden_dim - number of dimentions of hi+1\n",
    "        aggregator_type,    # type of aggregation\n",
    "        dropout_rate=0.5, # the dropout rate \n",
    "        n_cls=0.2,\n",
    "        n_hidden_layers=2,\n",
    "        activation='RELU'\n",
    "        ):\n",
    "        super(SAGE, self).__init__()\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.dropout = nn.Dropout(dropout_rate) # dropout layer\n",
    "        self.in_feats = in_feats\n",
    "        self.out_feats = out_feats\n",
    "        self.n_cls = n_cls\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.activation = activation\n",
    "        for i in range(n_hidden_layers):\n",
    "            if i == 0:\n",
    "                set_in_feats = self.in_feats\n",
    "            else:\n",
    "                set_in_feats = self.out_feats\n",
    "            layer = SAGEConv(\n",
    "                in_feats=set_in_feats,\n",
    "                out_feats=out_feats,\n",
    "                aggregator_type=aggregator_type,\n",
    "                feat_drop=dropout_rate,\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "        self.pooling = GlobalAttentionPooling(nn.Linear(self.out_feats, 1))\n",
    "            # --> aggregating the features into a single graph-level representation\n",
    "            # gate mechanism determines the importance of each node\n",
    "        self.output_layer = nn.Linear(self.out_feats, n_cls)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    def forward(self, graph, labels):\n",
    "        #feat = self.dropout(labels)\n",
    "        if (self.activation == 'RELU'):\n",
    "            h = F.relu(self.layers[0](graph, labels))\n",
    "        elif (self.activation == 'LeakyRELU'):\n",
    "            h = F.leaky_relu(self.layers[0](graph, labels), negative_slope=0.01)\n",
    "        #h = F.relu(self.layers[0](graph, labels))\n",
    "        h = self.dropout(h)\n",
    "        for i in range(self.n_hidden_layers):\n",
    "            # print(f\"SHAPE OF h IS: {graph.ndata['h'].size()}\")\n",
    "            # print(f\"NUM NODES: {graph.num_nodes()} \")\n",
    "            if i == 0:\n",
    "                continue\n",
    "            else:\n",
    "                if (self.activation == 'RELU'):\n",
    "                    h = F.relu(self.layers[i](graph, h))\n",
    "                elif (self.activation == 'LeakyRELU'):\n",
    "                    h = F.leaky_relu(self.layers[i](graph, h), negative_slope=0.01)\n",
    "                if i < self.n_hidden_layers - 1:\n",
    "                    h = self.dropout(h)\n",
    "        h = self.pooling(graph, h)#.squeeze\n",
    "        h = self.output_layer(h)\n",
    "        return h\n",
    "    def reset_parameters(self):\n",
    "        for layer in self.children():\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()\n",
    "            \n",
    "\n",
    "class EarlyStopping():\n",
    "    # implementing early stopping mechanism, but there is no printing method implemented\n",
    "    \"\"\"Early stops the training if neither validation loss nor validation\n",
    "    accuracy improves after their respective patience levels.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    patience_loss : int\n",
    "        How long to wait after last time validation loss improved.\n",
    "    patience_accuracy : int\n",
    "        How long to wait after last time validation accuracy improved.\n",
    "    verbose : bool\n",
    "        If True, prints a message for each validation metric improvement.\n",
    "    delta_loss : float\n",
    "        Minimum change in the validation loss to qualify as an improvement.\n",
    "    delta_accuracy : float\n",
    "        Minimum change in the validation accuracy to qualify as an improvement.\n",
    "    path : str\n",
    "        The file path where the model will be saved.\n",
    "    print_freq : int\n",
    "        The frequency at which to print messages during training.\n",
    "\n",
    "        - taken from Jozef's master's thesis\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        patience_loss=10,\n",
    "        patience_mcc=10,\n",
    "        verbose=True,\n",
    "        delta_loss=0.001,\n",
    "        delta_mcc=0.001,\n",
    "    ):\n",
    "        self.patience_loss = patience_loss\n",
    "        self.patience_mcc = patience_mcc\n",
    "        self.verbose = verbose\n",
    "        self.loss_counter = 0\n",
    "        self.mcc_counter = 0\n",
    "        self.best_loss = np.inf\n",
    "        self.best_mcc = -1             # stores best accuracy so far\n",
    "        self.early_stop = False             # bool indicating whether training should stop\n",
    "        self.delta_mcc = 0.001\n",
    "        self.delta_loss = 0.001\n",
    "        self.best_epoch = 0\n",
    "\n",
    "    # in this method, we are monitoring both the validation loss and accuracy\n",
    "    def __call__(self, val_loss, val_acc, val_mcc, model, epoch):   # earlier the method was called '__step__'\n",
    "        improved_loss = False\n",
    "        improved_mcc = False\n",
    "\n",
    "        if val_loss < self.best_loss - self.delta_loss:     # True only if val_loss improves beyond best_loss - delta_loss (treshold)\n",
    "            self.best_loss = val_loss                           # delta_loss is a small treshold, which ought to prevent fluctuations\n",
    "            self.loss_counter = 0                               # in the documentation implementation, there is a strict comparison without taking into account the fluctuations\n",
    "            improved_loss = True\n",
    "        else:\n",
    "            self.loss_counter += 1\n",
    "\n",
    "        if val_mcc > self.best_mcc + self.delta_mcc: # True if val_accuracy improves bexond best_accuracy + delta_accuracy (treshold)\n",
    "            self.best_mcc = val_mcc\n",
    "            self.mcc_counter = 0\n",
    "            improved_mcc = True\n",
    "        else:\n",
    "            self.mcc_counter += 1\n",
    "\n",
    "        if improved_loss or improved_mcc:              # if one of the metrics improves, we save the state as a checkpoint\n",
    "            self.save_checkpoint(model, val_loss, val_mcc, val_acc)\n",
    "            self.best_epoch = epoch\n",
    "\n",
    "        if self.loss_counter >= self.patience_loss and self.mcc_counter >= self.patience_mcc: #\n",
    "            self.early_stop = True\n",
    "            if self.verbose:\n",
    "                print(\"Early stopping triggered\")\n",
    "\n",
    "    def save_checkpoint(self, model, val_loss, val_mcc, val_acc):   # we save the model when either the accuracy or loss improves\n",
    "        torch.save(model.state_dict(), \"sage_checkpoint.pt\")\n",
    "        if self.verbose:\n",
    "            print(f\"Checkpoint saved, mcc: {val_mcc}, loss: {val_loss}, accuracy: {val_acc}\")\n",
    "\n",
    "class Training:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    def train_and_evaluate(\n",
    "        self,\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        early_stopping,\n",
    "        num_epochs,\n",
    "        # plot_curves=False,   for plotting curves\n",
    "        accumulation_steps=2,\n",
    "        scheduler=\"None\"\n",
    "    ):\n",
    "        train_losses, val_losses = [], []\n",
    "        scaler = GradScaler()       # initializing the gradient scaler\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            optimizer.zero_grad     # we initialize the gradients to zero, so that the gradients from the previous batch do not accumulate\n",
    "\n",
    "            for batch_idx, (batched_graph, labels) in enumerate(train_loader):  # train_loader ... data loader probiding batches of data\n",
    "                batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)   # self.device ... typically CPU or GPU\n",
    "                                                                                                # - by moving the data over there we ensure that both the data and the model are on the same device\n",
    "                                                                                                # that ensures no errors and consistency\n",
    "                batched_graph.ndata['h'] = batched_graph.ndata['h'].float().to(self.device) # Move node features to device - by bot TODO TODO TODO\n",
    "\n",
    "\n",
    "\n",
    "                with autocast():    # automatically selects the appropriate floating-point precision (to optimize performance - speeds up training, reduces memory usage)\n",
    "                    logits = model(batched_graph, batched_graph.ndata['h'].float()) # rund the model inside the autocast() context\n",
    "                    loss = criterion(logits, labels) / accumulation_steps   # we are using the gradient accumulation, because the batch size is too big to fit in memory\n",
    "                    # therefore we accumulate gradients over multiple batches before we update the weight --> loss is scaled down by the number of accumulation steps\n",
    "                scaler.scale(loss).backward()   # scaling the loss, preventing very small gradients from becoming zero (common issue in mixed precission training (autocast)\n",
    "                                                # .backward - computing the gradient using backpropagation\n",
    "                train_loss += loss.item() * accumulation_steps  # .item() ... converts loss from tensor to a python float\n",
    "                # we multiply by accumulation_steps to scale it back (we scaled down/divided earlier)\n",
    "                if (batch_idx + 1) % accumulation_steps == 0 or batch_idx == len(train_loader) - 1: # accumulating gradients for multiple batches before updatiing the model\n",
    "                # update does not happen after every batch\n",
    "                    scaler.step(optimizer)  # applying the scaled gradients to update model parameters\n",
    "                    scaler.update()         # ... updates the scaling factor for the next iteration\n",
    "                    # dynamically adjusts the scaling value to mantain stable gradients - if gradients too small, increases the scale and vice versa\n",
    "                    optimizer.zero_grad()   # initializing gradients to zero - clearing the gradients before the next batch\n",
    "\n",
    "            train_loss = train_loss/len(train_loader)   # getting the average loss per batch\n",
    "            train_losses.append(train_loss)\n",
    "\n",
    "            validation_loss = 0.0\n",
    "            validation_accuraccy = 0.0\n",
    "            num_val_correct = 0         # number of correctly predicted samples\n",
    "            num_total = 0               # total number of samples\n",
    "            TP, TN, FP, FN = 0, 0, 0, 0\n",
    "            if val_loader is not None:  # val_loader ... validation dataset, we check, whether it is not null --> then there would be no validation\n",
    "                model.eval()            # we put the model into the evaluation mode - we turn off the dropout layers and disable the batch normalization updates\n",
    "                                        # --> validation results are consistent and unaffected by randomness\n",
    "                with torch.no_grad():   # we prevent pytorch from storing gradients during validation --> saves memory and improves performance\n",
    "                    for batched_graph, labels in val_loader:        # iterates over mini-batches of validation data\n",
    "                        batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)   # we move the input and labels to the correct device (CPU, GPU)\n",
    "\n",
    "                        batched_graph.ndata['h'] = batched_graph.ndata['h'].to(self.device) # TODO TODO TODO - chatova práce\n",
    "\n",
    "                        with autocast():    # automatically selects the appropriate floating-point precision (to optimize performance - speeds up training, reduces memory usage)\n",
    "                            logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "                            # graph structure (batched_graph) is passed on to the model, node features (batched_graph.ndata['h']) serve as input data\n",
    "                                # --> The GNN layers aggregate information from neighboring nodes\n",
    "                                # final layer outputs predictions (logits) for node/graph classification\n",
    "                            loss = criterion(logits, labels)    # we compute the loss\n",
    "                        validation_loss += loss             # accumulating loss over all batches\n",
    "                        _, predicted = torch.max(logits.data, 1)    # getting the predicted class (highest probability)\n",
    "                        num_total += labels.size(0)             # updating the total number of samples\n",
    "                        num_val_correct += (predicted == labels).sum().item()   # adds up the number of correct predictions\n",
    "                        TP += ((predicted == 1) & (labels == 1)).sum().item()\n",
    "                        TN += ((predicted == 0) & (labels == 0)).sum().item()\n",
    "                        FP += ((predicted == 1) & (labels == 0)).sum().item()\n",
    "                        FN += ((predicted == 0) & (labels == 1)).sum().item()\n",
    "\n",
    "                    num = TP * TN - FP * FN\n",
    "                    den = math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "                    validation_mcc = num / den if den > 0 else 0\n",
    "                    validation_loss = validation_loss/len(val_loader)   # we get the average loss\n",
    "                    val_losses.append(validation_loss)\n",
    "                    validation_accuraccy = num_val_correct/num_total    # saving for early stopping\n",
    "                    if early_stopping:  # checking if early stopping is not None\n",
    "                        early_stopping(validation_loss, validation_accuraccy, validation_mcc, model, epoch + 1)\n",
    "                        if early_stopping.early_stop:\n",
    "                            print(f\"Early stopping triggered at epoch {epoch + 1}\")\n",
    "                            break\n",
    "                    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "                        print(f'Epoch {epoch + 1}/{num_epochs}'\n",
    "                              f'Train loss: {train_loss:.4f}'\n",
    "                              f'Val loss: {validation_loss:.4f}'\n",
    "                              f'Val accuracy: {100 * validation_accuraccy:.2f}% '\n",
    "                              f'MCC: {validation_mcc}')\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(validation_loss)\n",
    "            elif scheduler is not None:  # using the scheduler\n",
    "                scheduler.step()\n",
    "                # plotting of curves might be implemented here (TODO)\n",
    "\n",
    "        # there the plot curves method might be implemented (another TODO possibility)\n",
    "\n",
    "    def evaluate_on_test(self, model, test_loader, criterion, run_id=1):\n",
    "        model.eval()    # we put model into the evaluation model (ensuring that gradients won't be computed)\n",
    "        test_loss = 0.0\n",
    "        all_preds = []        # storing all predicted labels\n",
    "        all_labels = []       # storing all labels (true labels)\n",
    "        all_proba = []\n",
    "        with torch.no_grad():       # disabling calculations of gradient\n",
    "            for batched_graph, labels in test_loader:       # iterates over mini-batches of validation data\n",
    "                batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)       # we move the input and labels to the correct device (CPU, GPU)\n",
    "                logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "                loss = criterion(logits, labels)\n",
    "                test_loss += loss.item()\n",
    "                preds = torch.argmax(logits, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy()) # moving predictions and labels to CPU and converting them to NumPy arrays\n",
    "                #all_labels.extend(preds.cpu().numpy()) # (they get stored in all_pred ad all_labels variables)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_proba.extend(torch.softmax(logits, dim=1)[:, 1].cpu().numpy()) \n",
    "                #all_proba\n",
    "        test_loss = test_loss/len(test_loader)  # averages the total loss over all test batches\n",
    "        # calculating evaluation metrics:\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        precision = precision_score(all_labels, all_preds)\n",
    "        recall = recall_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds)\n",
    "        roc_auc = roc_auc_score(all_labels, all_preds)\n",
    "        matthews_corr = matthews_corrcoef(all_labels, all_preds)\n",
    "         # Compute ROC curve ---------\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_proba)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        # Plot ROC Curve --------\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Random classifier\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.show()\n",
    "        plt.savefig(\"sage_plot.png\")\n",
    "\n",
    "        # confusion matrix\n",
    "        conf_mat = confusion_matrix(all_labels, all_preds)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=conf_mat)\n",
    "        disp.plot(cmap='Blues')\n",
    "        plt.savefig(\"conf_mat_sage.png\")\n",
    "        # possible to save here (TODO) ?\n",
    "\n",
    "        results_dataFrame = pd.DataFrame({\n",
    "            'Test Loss': [test_loss],\n",
    "            'Accuracy': [accuracy],\n",
    "            'Precision': [precision],\n",
    "            'Recall': [recall],\n",
    "            'F1-Score': [f1],\n",
    "            'MCC': [matthews_corr],\n",
    "            'ROC-AUC': [roc_auc]\n",
    "        })\n",
    "        results_dataFrame.to_csv('test_results_SAGE.csv')  # possible to adjust settings\n",
    "        print(f\"Test Loss: {test_loss}\")\n",
    "        print(f\"Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}, MCC: {matthews_corr}, ROC-AUC: {roc_auc}\")\n",
    "\n",
    "def collate(samples):   # converts individual graph samples into a single batch for training\n",
    "                        # input ... samples - a list of tuples, where each tuple contains (graph, label)\n",
    "                        # graph ... dgl graph object, label ... a target label\n",
    "    graphs, labels = map(list, zip(*samples))   # unpacking graphs and labels from the list of tuples and converting them into separate lists\n",
    "    batched_graph = dgl.batch(graphs)           # batching the graphs (sdružování grafů)\n",
    "    labels = torch.tensor(labels, dtype=torch.long) # converting list of labels into a PyTorch tensor\n",
    "    return batched_graph, labels\n",
    "                        # batched graph ... single batched graph combining individual graphs\n",
    "                        # labels ... tensor of labels for the batch\n",
    "\n",
    "class Hyperparameter_optimizer:     # optuna ... library for automatic hyperparameter tuning, selecting the best hyperparameters based on validation loss\n",
    "    def __init__(\n",
    "        self,\n",
    "        device,                     # GPU/CPU\n",
    "        subset_train_graphs,        # training data (graphs + labels)\n",
    "        subset_train_labels,\n",
    "        subset_val_graphs,          # validation data (graphs + labels)\n",
    "        subset_val_labels,\n",
    "        num_trials,                 # number of trials for optimization\n",
    "        num_epochs,                  # number of training epochs per trial\n",
    "        random_state\n",
    "    ):\n",
    "        self.device = device        # setting all of the parameters of the class\n",
    "        self.subset_train_graphs = subset_train_graphs\n",
    "        self.subset_train_labels = subset_train_labels\n",
    "        self.subset_val_graphs = subset_val_graphs\n",
    "        self.subset_val_labels = subset_val_labels\n",
    "        self.num_trials = num_trials\n",
    "        self.num_epochs = num_epochs\n",
    "        self.random_state = random_state\n",
    "    def objective(self, trial):     # sample hyperparameters, optuna is doing a \"smart\" selection of hyperparameters, which are most likely to give the best result\n",
    "        # optuna does not try all the combinations, since that would simply take too long\n",
    "        in_feats = 74\n",
    "        #hidden_dim = trial.suggest_int('hidden_dim', 74, 256)\n",
    "        hidden_dim = trial.suggest_int('hidden_dim', 84, 147)\n",
    "        \n",
    "        #dropout_rate = trial.suggest_float('dropout_rate', 0.05, 0.5)\n",
    "        dropout_rate = trial.suggest_float('dropout_rate', 0.11, 0.21)\n",
    "        \n",
    "        #aggregator_type = trial.suggest_categorical('aggregator_type', ['mean', 'gcn', 'pool', 'lstm'])\n",
    "        aggregator_type = trial.suggest_categorical('aggregator_type', ['pool'])\n",
    "        \n",
    "        #lr = trial.suggest_float('lr', 1e-6, 1e-1, log=True)\n",
    "        lr = trial.suggest_float('lr', 1e-4, 1e-2, log=True)\n",
    "        \n",
    "        #batch_size = trial.suggest_categorical('batch_size', [32, 64, 128, 256])#, 512])\n",
    "        batch_size = trial.suggest_categorical('batch_size', [128, 256])\n",
    "        \n",
    "        #n_hidden_layers = trial.suggest_int('n_hidden_layers', 1, 6)\n",
    "        n_hidden_layers = trial.suggest_int('n_hidden_layers', 1, 3)\n",
    "        \n",
    "        #lr_scheduler = trial.suggest_categorical('lr_scheduler', ['None', 'StepLR', 'ExponentialLR'])\n",
    "        lr_scheduler = trial.suggest_categorical('lr_scheduler', ['StepLR', 'ExponentialLR'])\n",
    "        \n",
    "        #activation = trial.suggest_categorical('activation', ['RELU', 'LeakyRELU'])\n",
    "        activation = trial.suggest_categorical('activation', ['RELU'])\n",
    "\n",
    "        model = SAGE(              # initializing model with sampled hyperparameters\n",
    "            in_feats=74,\n",
    "            out_feats=hidden_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            aggregator_type=aggregator_type,\n",
    "            n_cls=2,\n",
    "            n_hidden_layers=n_hidden_layers,\n",
    "            activation = activation             # set differently?? TODO TODO TODO\n",
    "        #)      TODO TODO TODO - this is where the model is moved to the device (written by bot)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        class_counts = np.bincount(self.subset_train_labels)\n",
    "        class_counts[class_counts == 0] = 1\n",
    "        class_weights = 1.0 / class_counts\n",
    "        class_weights = torch.tensor(class_weights, dtype=torch.float32).to(self.device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)   # using Adam optimizer\n",
    "        #criterion = nn.CrossEntropyLoss().to(self.device)   # criterion for the classification task\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights).to(self.device)   # criterion for the classification task\n",
    "        # creating Dataloaders for training and validation - batches graphs and labels for training & validation\n",
    "            # Dataloaders in dgl ... handles graphs instead of regular tensors, creates mini-batches for efficient training, allows parallel processing, ...\n",
    "                                    # schuffles training data to prevent bias\n",
    "        scheduler_obj = None\n",
    "        if lr_scheduler == 'None':\n",
    "            scheduler_obj = None\n",
    "        elif lr_scheduler == 'StepLR':\n",
    "            #step_size = trial.suggest_int('step_size', 1, 20)\n",
    "            #step_size = trial.suggest_int('step_size', 14, 20)\n",
    "            step_size = trial.suggest_int('step_size', 15, 20)\n",
    "            #gamma_step = trial.suggest_float('gamma_step', 0.5, 0.99)\n",
    "            gamma_step = trial.suggest_float('gamma_step', 0.79, 0.93)\n",
    "            scheduler_obj = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma_step)\n",
    "        elif lr_scheduler == 'ExponentialLR':\n",
    "            #gamma_exp = trial.suggest_float('gamma_exp', 0.1, 0.99)\n",
    "            gamma_exp = trial.suggest_float('gamma_exp', 0.9872745703157462, 0.9872745703157462)\n",
    "            scheduler_obj = optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma_exp)    \n",
    "            \n",
    "        train_loader = GraphDataLoader(\n",
    "            list(zip(self.subset_train_graphs, self.subset_train_labels)),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            collate_fn=collate,         # custom function for combining graphs into batches\n",
    "            num_workers=0)                            # debugging TODO TODO TODO\n",
    "            #num_workers=8)  # debugging TODO TODO TODO\n",
    "        val_loader = GraphDataLoader(\n",
    "            list(zip(self.subset_val_graphs, self.subset_val_labels)),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,              # we do not want to schuffle the data - we want them fixed for consistency\n",
    "            collate_fn=collate,\n",
    "            num_workers=0)\n",
    "            #num_workers=8)\n",
    "\n",
    "                          # we set the model into the training mode, but do not do the training itself --> therefore the following function\n",
    "        for epoch in range(self.num_epochs):    # training the model\n",
    "            model.train() \n",
    "            for batched_graph, labels in train_loader:\n",
    "                batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)   # moving graphs and labels into the device CPU/GPU\n",
    "                batched_graph.ndata['h'] = batched_graph.ndata['h'].to(self.device) # TODO TODO TODO - chatova práce\n",
    "                optimizer.zero_grad()\n",
    "                logits = model(batched_graph, batched_graph.ndata['h'].float())     # this line calls the model's forward pass using two inputs\n",
    "                        # batched graph ... graph structure containing connectivity information\n",
    "                        # second argument ... node features extracted from the graph, converted to floating point numbers\n",
    "                loss = criterion(logits, labels)\n",
    "                loss.backward()     # we calculated loss and we backpropagate the gradients\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batched_graph, labels in val_loader:\n",
    "                    batched_graph, labels = batched_graph.to(self.device), labels.to(self.device)\n",
    "                    batched_graph.ndata['h'] = batched_graph.ndata['h'].to(self.device) # TODO TODO TODO - chatova práce\n",
    "                    optimizer.zero_grad()\n",
    "                    logits = model(batched_graph, batched_graph.ndata['h'].float())\n",
    "                    loss = criterion(logits, labels)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            val_loss = val_loss/len(val_loader)\n",
    "            trial.report(val_loss, epoch)       # we use this line to report the current validation loss at a given epoch for the ongoing trial\n",
    "                                                    # optuna is collecting these intermediates results, optuna can then stop the non-promising trials early\n",
    "            if lr_scheduler != 'None':  # using the scheduler\n",
    "                scheduler_obj.step()\n",
    "            if trial.should_prune():            # asking optuna, if trial should be pruned (\"ended\")\n",
    "                raise optuna.TrialPruned()  # TODO TODO\n",
    "        return val_loss\n",
    "\n",
    "    def optimize(self):     # running the whole hyperparameter optimization using optuna\n",
    "        sampler = optuna.samplers.TPESampler(seed=self.random_state)\n",
    "        study = optuna.create_study(direction='minimize', pruner=MedianPruner(), sampler=sampler)\n",
    "            # Medianpruner ... stops unpromising trials based on the median performance so far\n",
    "        study.optimize(self.objective, n_trials=self.num_trials, n_jobs=1)  # running optimization process, specifies, how many different sets of hyperparameters (different trials) to try\n",
    "        best_hyperparameters = study.best_trial.params\n",
    "        with open(f'sage_best_hyperparams.json', 'w') as f:    # saving the trials into a JSON file\n",
    "            json.dump(best_hyperparameters, f)\n",
    "        print(f\"Best hyperparameters are {best_hyperparameters}.\")  # printing the best hyperparameters\n",
    "        top_trials = sorted(study.trials, key=lambda t: t.value)[:10]\n",
    "\n",
    "        for i, trial in enumerate(top_trials, 1):\n",
    "            print(f\"\\nTrial #{i}\")\n",
    "            print(f\"  Value (Objective): {trial.value}\")\n",
    "            print(f\"  Params: {trial.params}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_loading(address_train, address_val, address_test, RANDOM_STATE, part=1):\n",
    "    train_graphs, train_labels_dictionary = dgl.load_graphs(address_train)\n",
    "    train_labels = train_labels_dictionary['labels']\n",
    "    train_labels = train_labels.squeeze()\n",
    "    train_labels = train_labels.numpy()\n",
    "\n",
    "    val_graphs, val_labels_dictionary = dgl.load_graphs(address_val)\n",
    "    val_labels = val_labels_dictionary['labels']\n",
    "    val_labels = val_labels.squeeze()\n",
    "    val_labels = val_labels.numpy()\n",
    "\n",
    "    test_graphs, test_labels_dictionary = dgl.load_graphs(address_test)\n",
    "    test_labels = test_labels_dictionary['labels']\n",
    "    test_labels = test_labels.squeeze()\n",
    "    test_labels = test_labels.numpy()\n",
    "\n",
    "    subset_train_indices = np.random.choice(\n",
    "        len(train_graphs), size=int(len(train_graphs) * 0.2), replace=False # we choose 20% of the training graphs\n",
    "    )   # replace=False ensures that no index is selected more than once\n",
    "\n",
    "    subset_train_graphs = [train_graphs[i] for i in subset_train_indices] # we store the corresponding graphs\n",
    "    subset_train_labels = train_labels[subset_train_indices]    # we store the corresponding labels\n",
    "\n",
    "    subset_val_indices = np.random.choice(\n",
    "        len(val_graphs), size=int(len(val_graphs) * 0.2), replace=False\n",
    "    )\n",
    "    subset_val_graphs = [train_graphs[i] for i in subset_val_indices]\n",
    "    subset_val_labels = val_labels[subset_val_indices]\n",
    "\n",
    "    combined_train_graphs = train_graphs + val_graphs # + ... list concatenation, two lists are merged into one\n",
    "    combined_train_labels = np.concatenate((train_labels, val_labels))  # two arrays merged into one\n",
    "\n",
    "    graphs = combined_train_graphs + test_graphs\n",
    "    labels_numpy = np.concatenate((combined_train_labels, test_labels))\n",
    "\n",
    "    print(\n",
    "        f'Train: {len(train_graphs)},'\n",
    "        f'Val: {len(val_graphs)},'\n",
    "        f'Test: {len(test_graphs)},'\n",
    "        f'Val + Train combined: {len(combined_train_graphs)}'\n",
    "    )\n",
    "    print(\"\\nData loading completed\\n\")\n",
    "    sys.stdout.flush()\n",
    "    return {\n",
    "        \"graphs\": (graphs, labels_numpy),\n",
    "        \"train\": (train_graphs, train_labels),\n",
    "        \"val\": (val_graphs, val_labels),\n",
    "        \"test\": (test_graphs, test_labels),\n",
    "        \"subset_train\": (subset_train_graphs, subset_train_labels),\n",
    "        \"subset_val\": (subset_val_graphs, subset_val_labels),\n",
    "        \"combined_train\": (combined_train_graphs, combined_train_labels),\n",
    "    }\n",
    "    \n",
    "def main_train_loop(run_number):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # TODO ?? what is cuda??\n",
    "    RANDOM_STATE = 42\n",
    "    # setting the random state:\n",
    "    random.seed(RANDOM_STATE)\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    torch.manual_seed(RANDOM_STATE)\n",
    "    torch.cuda.manual_seed_all(RANDOM_STATE)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(RANDOM_STATE)\n",
    "\n",
    "    \n",
    "    num_trials = 160\n",
    "    num_epochs = 100\n",
    "    tune_hyperparams = False\n",
    "    split_num = run_number\n",
    "    \n",
    "    data = data_loading(f\"hERG_graphs/herg_graphs_train{split_num}.bin\", \n",
    "                        f\"hERG_graphs/herg_graphs_val{split_num}.bin\",\n",
    "                        f\"hERG_graphs/herg_graphs_test{split_num}.bin\", RANDOM_STATE, part=1)\n",
    "    graphs,_ = data[\"graphs\"]\n",
    "    train_graphs, train_labels = data[\"train\"]\n",
    "    val_graphs, val_labels = data[\"val\"]\n",
    "    test_graphs, test_labels = data[\"test\"]\n",
    "    subset_train_graphs, subset_train_labels = data[\"subset_train\"]\n",
    "    subset_val_graphs, subset_val_labels = data[\"subset_val\"]\n",
    "    combined_train_graphs, combined_train_labels = data[\"combined_train\"]\n",
    "    \n",
    "\n",
    "    print('Hyperparameter optimization...\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if tune_hyperparams:\n",
    "        optimizer = Hyperparameter_optimizer(\n",
    "            device,\n",
    "            subset_train_graphs = train_graphs,\n",
    "            subset_train_labels = train_labels,\n",
    "            subset_val_graphs = val_graphs,\n",
    "            subset_val_labels = val_labels,\n",
    "            #subset_train_graphs = subset_train_graphs,\n",
    "            #subset_train_labels = subset_train_labels,\n",
    "            #subset_val_graphs = subset_val_graphs,\n",
    "            #subset_val_labels = subset_val_labels,\n",
    "            #num_trials=200,\n",
    "            num_trials=num_trials,\n",
    "            #num_epochs=100)   # TODO TODO TODO DEBUGGING\n",
    "            num_epochs=num_epochs,\n",
    "            random_state=RANDOM_STATE)\n",
    "\n",
    "        optimizer.optimize()\n",
    "    \n",
    "        print(\"Hyperparameter optimization done.\")\n",
    "        sys.stdout.flush()\n",
    "        print(\"\")\n",
    "\n",
    "#def retrain_using_best_parameters(train_graphs, val_graphs, test_graphs):\n",
    "    # we load the data using GraphDataLoader\n",
    "    with open(f'sage_best_hyperparams.json', 'r') as f:\n",
    "        best_hyperparameters = json.load(f)     # we load the best hyperparameters\n",
    "    print(best_hyperparameters)\n",
    "    train_loader = GraphDataLoader(\n",
    "        list(zip(train_graphs, train_labels)),\n",
    "        batch_size=best_hyperparameters['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=collate,\n",
    "        num_workers=0)\n",
    "        #num_workers=8)\n",
    "    val_loader = GraphDataLoader(\n",
    "        list(zip(val_graphs, val_labels)),\n",
    "        batch_size=best_hyperparameters['batch_size'],\n",
    "        shuffle=False,\n",
    "        collate_fn=collate,\n",
    "        num_workers=0)\n",
    "        #num_workers=8)\n",
    "    test_loader = GraphDataLoader(\n",
    "        list(zip(test_graphs, test_labels)),\n",
    "        batch_size=best_hyperparameters['batch_size'],\n",
    "        shuffle=False,\n",
    "        collate_fn=collate,\n",
    "        num_workers=0)\n",
    "        #num_workers=8)\n",
    "    combined_test_val_loader = GraphDataLoader(\n",
    "        list(\n",
    "            zip(\n",
    "                combined_train_graphs, combined_train_labels\n",
    "            )),\n",
    "        batch_size=best_hyperparameters['batch_size'],\n",
    "        shuffle=True,\n",
    "        collate_fn=collate,\n",
    "        num_workers=0)\n",
    "        #num_workers=8)\n",
    "    print(\"Dataloaders done.\")\n",
    "    print(\"Retraining using best parameters...\")\n",
    "    print(f\"Number of available node features (in_feats): {graphs[0].ndata['h'].shape[1]}\")  # Check available node features\n",
    "    model = SAGE(              # initializing model with sampled hyperparameters\n",
    "        in_feats=74,    # adjusting according to the dataset TODO TODO TODO !!!\n",
    "        out_feats=best_hyperparameters['hidden_dim'],\n",
    "        dropout_rate=best_hyperparameters['dropout_rate'],\n",
    "        aggregator_type=best_hyperparameters['aggregator_type'],\n",
    "        n_cls=2,\n",
    "        n_hidden_layers=best_hyperparameters['n_hidden_layers'],\n",
    "        activation = best_hyperparameters['activation']\n",
    "    ).to(device)\n",
    "    model.reset_parameters()    # reseting the parameters of the model before retraining\n",
    "    \n",
    "    class_counts = np.bincount(combined_train_labels)\n",
    "    class_counts[class_counts == 0] = 1\n",
    "    class_weights = 1.0 / class_counts\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_hyperparameters['lr'])\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if best_hyperparameters['lr_scheduler'] == 'None':\n",
    "        lr_scheduler = None\n",
    "    elif best_hyperparameters['lr_scheduler'] == 'StepLR':\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, best_hyperparameters['step_size'], best_hyperparameters['gamma_step'])\n",
    "    elif best_hyperparameters['lr_scheduler'] == 'ExponentialLR':\n",
    "         lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, best_hyperparameters['gamma_exp'])\n",
    "\n",
    "    #early_stopping = EarlyStopping(patience_loss=10, patience_accuracy=10, verbose=False, delta_loss=0.001, delta_accuracy=0.001) - PUVODNI SETTING!\n",
    "    early_stopping = EarlyStopping(patience_loss=80, patience_mcc=80, verbose=False, delta_loss=0.001, delta_mcc=0.001)\n",
    "    training = Training(device)\n",
    "    training.train_and_evaluate(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        early_stopping,\n",
    "        1000,\n",
    "        #1000,                # Number of epochs TODO TODO TODO ... this one WAS 300, for debugging purposes 5\n",
    "        scheduler=lr_scheduler\n",
    "    )\n",
    "    optimal_epoch = early_stopping.best_epoch\n",
    "    print(f\"The best epoch was {optimal_epoch}\") \n",
    "    model.reset_parameters()    # before we train the model on test + val dataset, we reset all the parameters\n",
    "    print(\"Training done.\")\n",
    "    print(\"Final training...\")\n",
    "    \n",
    "    class_counts = np.bincount(combined_train_labels)\n",
    "    class_counts[class_counts == 0] = 1\n",
    "    class_weights = 1.0 / class_counts\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_hyperparameters['lr'])\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "    \n",
    "    lr_scheduler = None\n",
    "    if best_hyperparameters['lr_scheduler'] == 'None':\n",
    "        lr_scheduler = None\n",
    "    elif best_hyperparameters['lr_scheduler'] == 'StepLR':\n",
    "        lr_scheduler = optim.lr_scheduler.StepLR(optimizer, best_hyperparameters['step_size'], best_hyperparameters['gamma_step'])\n",
    "    elif best_hyperparameters['lr_scheduler'] == 'ExponentialLR':\n",
    "         lr_scheduler = optim.lr_scheduler.ExponentialLR(optimizer, best_hyperparameters['gamma_exp'])\n",
    "    \n",
    "    \n",
    "    training.train_and_evaluate(\n",
    "        model,\n",
    "        combined_test_val_loader,\n",
    "        None,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        None,\n",
    "        optimal_epoch,\n",
    "        scheduler=lr_scheduler\n",
    "    )\n",
    "    torch.save(model.state_dict(), f'sage_model.pt')\n",
    "    print(\"Training done.\")\n",
    "    print(\"Evaluating on test_dataset\")\n",
    "    training.evaluate_on_test(model, test_loader, criterion)\n",
    "    print(\"Evaluation done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # This ensures that multiprocessing works safely when used with PyTorch DataLoader\n",
    "    import multiprocessing\n",
    "    multiprocessing.set_start_method('spawn', force=True)  # Ensure spawn method is used for safe process spawning\n",
    "\n",
    "\n",
    "    # odstranit!\n",
    "    #run_number = 1\n",
    "    main_train_loop(run_number)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b539f43-48dc-4e53-b493-9531ad127fbb",
   "metadata": {
    "papermill": {
     "duration": 0.007357,
     "end_time": "2025-06-02T14:34:19.210266",
     "exception": false,
     "start_time": "2025-06-02T14:34:19.202909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 347.877058,
   "end_time": "2025-06-02T14:34:20.342582",
   "environment_variables": {},
   "exception": null,
   "input_path": "GraphSAGE_model.ipynb",
   "output_path": "run_out_hERG/GraphSAGE_out8.ipynb",
   "parameters": {
    "run_number": 8
   },
   "start_time": "2025-06-02T14:28:32.465524",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}